{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from stop_words import get_stop_words\n",
    "import string\n",
    "import numpy as np\n",
    "import lda\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stop_words = get_stop_words('english') #pulls in stop words from stop_words library\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "vocab = []\n",
    "print(vocab)\n",
    "corpus = []\n",
    "\n",
    "folders = ['Transcripts1/', 'Transcripts2/', 'Transcripts3/']\n",
    "\n",
    "for folder in folders:\n",
    "\n",
    "    transcript_path = './transcriptions/' + folder\n",
    "    transcript_files = os.listdir(transcript_path)\n",
    "    \n",
    "    for file in transcript_files:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(transcript_path + file) as myfile:\n",
    "                raw = myfile.read().replace('\\n', '')\n",
    "                raw = raw.lower().translate(translator) #remove punctutation\n",
    "                raw_words = raw.split()\n",
    "                result_words = [word for word in raw_words if word.lower() not in stop_words] #clean/filter text\n",
    "                #print(result_words)\n",
    "                #corpus = corpus + [result_words\n",
    "                vocab = vocab + result_words\n",
    "                corpus.append(' '.join(result_words)) #add text to corpus\n",
    "                #entry.text = result_words #update text for specific entry\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "#print(corpus)\n",
    "X = vectorizer.fit_transform(corpus) #count vectorizer for all words\n",
    "X_names = vectorizer.get_feature_names() #names = different words in vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:guidedlda:n_documents: 1729\n",
      "INFO:guidedlda:vocab_size: 9459\n",
      "INFO:guidedlda:n_words: 148397\n",
      "INFO:guidedlda:n_topics: 5\n",
      "INFO:guidedlda:n_iter: 2000\n",
      "WARNING:guidedlda:all zero row in document-term matrix found\n",
      "INFO:guidedlda:<0> log likelihood: -1311829\n",
      "INFO:guidedlda:<20> log likelihood: -1087548\n",
      "INFO:guidedlda:<40> log likelihood: -1069670\n",
      "INFO:guidedlda:<60> log likelihood: -1061755\n",
      "INFO:guidedlda:<80> log likelihood: -1057839\n",
      "INFO:guidedlda:<100> log likelihood: -1055185\n",
      "INFO:guidedlda:<120> log likelihood: -1052328\n",
      "INFO:guidedlda:<140> log likelihood: -1050952\n",
      "INFO:guidedlda:<160> log likelihood: -1049846\n",
      "INFO:guidedlda:<180> log likelihood: -1047468\n",
      "INFO:guidedlda:<200> log likelihood: -1046963\n",
      "INFO:guidedlda:<220> log likelihood: -1045594\n",
      "INFO:guidedlda:<240> log likelihood: -1045382\n",
      "INFO:guidedlda:<260> log likelihood: -1044796\n",
      "INFO:guidedlda:<280> log likelihood: -1044475\n",
      "INFO:guidedlda:<300> log likelihood: -1043677\n",
      "INFO:guidedlda:<320> log likelihood: -1043653\n",
      "INFO:guidedlda:<340> log likelihood: -1043147\n",
      "INFO:guidedlda:<360> log likelihood: -1042622\n",
      "INFO:guidedlda:<380> log likelihood: -1041857\n",
      "INFO:guidedlda:<400> log likelihood: -1042389\n",
      "INFO:guidedlda:<420> log likelihood: -1041616\n",
      "INFO:guidedlda:<440> log likelihood: -1040801\n",
      "INFO:guidedlda:<460> log likelihood: -1040220\n",
      "INFO:guidedlda:<480> log likelihood: -1041204\n",
      "INFO:guidedlda:<500> log likelihood: -1040952\n",
      "INFO:guidedlda:<520> log likelihood: -1040259\n",
      "INFO:guidedlda:<540> log likelihood: -1039475\n",
      "INFO:guidedlda:<560> log likelihood: -1039316\n",
      "INFO:guidedlda:<580> log likelihood: -1039590\n",
      "INFO:guidedlda:<600> log likelihood: -1039491\n",
      "INFO:guidedlda:<620> log likelihood: -1039443\n",
      "INFO:guidedlda:<640> log likelihood: -1038802\n",
      "INFO:guidedlda:<660> log likelihood: -1039203\n",
      "INFO:guidedlda:<680> log likelihood: -1038736\n",
      "INFO:guidedlda:<700> log likelihood: -1038958\n",
      "INFO:guidedlda:<720> log likelihood: -1039051\n",
      "INFO:guidedlda:<740> log likelihood: -1038935\n",
      "INFO:guidedlda:<760> log likelihood: -1039027\n",
      "INFO:guidedlda:<780> log likelihood: -1038868\n",
      "INFO:guidedlda:<800> log likelihood: -1038904\n",
      "INFO:guidedlda:<820> log likelihood: -1038621\n",
      "INFO:guidedlda:<840> log likelihood: -1038356\n",
      "INFO:guidedlda:<860> log likelihood: -1038265\n",
      "INFO:guidedlda:<880> log likelihood: -1037651\n",
      "INFO:guidedlda:<900> log likelihood: -1038724\n",
      "INFO:guidedlda:<920> log likelihood: -1038519\n",
      "INFO:guidedlda:<940> log likelihood: -1038769\n",
      "INFO:guidedlda:<960> log likelihood: -1038983\n",
      "INFO:guidedlda:<980> log likelihood: -1039020\n",
      "INFO:guidedlda:<1000> log likelihood: -1038569\n",
      "INFO:guidedlda:<1020> log likelihood: -1037748\n",
      "INFO:guidedlda:<1040> log likelihood: -1037653\n",
      "INFO:guidedlda:<1060> log likelihood: -1038040\n",
      "INFO:guidedlda:<1080> log likelihood: -1038226\n",
      "INFO:guidedlda:<1100> log likelihood: -1038163\n",
      "INFO:guidedlda:<1120> log likelihood: -1038308\n",
      "INFO:guidedlda:<1140> log likelihood: -1038057\n",
      "INFO:guidedlda:<1160> log likelihood: -1037697\n",
      "INFO:guidedlda:<1180> log likelihood: -1038246\n",
      "INFO:guidedlda:<1200> log likelihood: -1037992\n",
      "INFO:guidedlda:<1220> log likelihood: -1037958\n",
      "INFO:guidedlda:<1240> log likelihood: -1037741\n",
      "INFO:guidedlda:<1260> log likelihood: -1037864\n",
      "INFO:guidedlda:<1280> log likelihood: -1037375\n",
      "INFO:guidedlda:<1300> log likelihood: -1037672\n",
      "INFO:guidedlda:<1320> log likelihood: -1037741\n",
      "INFO:guidedlda:<1340> log likelihood: -1036768\n",
      "INFO:guidedlda:<1360> log likelihood: -1036890\n",
      "INFO:guidedlda:<1380> log likelihood: -1036950\n",
      "INFO:guidedlda:<1400> log likelihood: -1036853\n",
      "INFO:guidedlda:<1420> log likelihood: -1037238\n",
      "INFO:guidedlda:<1440> log likelihood: -1036826\n",
      "INFO:guidedlda:<1460> log likelihood: -1036692\n",
      "INFO:guidedlda:<1480> log likelihood: -1037300\n",
      "INFO:guidedlda:<1500> log likelihood: -1036991\n",
      "INFO:guidedlda:<1520> log likelihood: -1037122\n",
      "INFO:guidedlda:<1540> log likelihood: -1037118\n",
      "INFO:guidedlda:<1560> log likelihood: -1037512\n",
      "INFO:guidedlda:<1580> log likelihood: -1037249\n",
      "INFO:guidedlda:<1600> log likelihood: -1036553\n",
      "INFO:guidedlda:<1620> log likelihood: -1036872\n",
      "INFO:guidedlda:<1640> log likelihood: -1036818\n",
      "INFO:guidedlda:<1660> log likelihood: -1036755\n",
      "INFO:guidedlda:<1680> log likelihood: -1036905\n",
      "INFO:guidedlda:<1700> log likelihood: -1037031\n",
      "INFO:guidedlda:<1720> log likelihood: -1036206\n",
      "INFO:guidedlda:<1740> log likelihood: -1036749\n",
      "INFO:guidedlda:<1760> log likelihood: -1036908\n",
      "INFO:guidedlda:<1780> log likelihood: -1036720\n",
      "INFO:guidedlda:<1800> log likelihood: -1037057\n",
      "INFO:guidedlda:<1820> log likelihood: -1036276\n",
      "INFO:guidedlda:<1840> log likelihood: -1036453\n",
      "INFO:guidedlda:<1860> log likelihood: -1036486\n",
      "INFO:guidedlda:<1880> log likelihood: -1037555\n",
      "INFO:guidedlda:<1900> log likelihood: -1036787\n",
      "INFO:guidedlda:<1920> log likelihood: -1037344\n",
      "INFO:guidedlda:<1940> log likelihood: -1037531\n",
      "INFO:guidedlda:<1960> log likelihood: -1037048\n",
      "INFO:guidedlda:<1980> log likelihood: -1036934\n",
      "INFO:guidedlda:<1999> log likelihood: -1036894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<guidedlda.guidedlda.GuidedLDA at 0x10a557be0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Guided LDA\n",
    "import numpy as np\n",
    "import guidedlda\n",
    "\n",
    "\n",
    "vocab = X_names\n",
    "word2id = dict((v, idx) for idx, v in enumerate(vocab))\n",
    "\n",
    "model = guidedlda.GuidedLDA(n_topics=5, n_iter=2000, random_state=7, refresh=20)\n",
    "\n",
    "seed_topic_list = [['monthly', 'gift', 'donor', 'increase', 'upgrade'], \n",
    "                   ['syria', 'myanmar', 'refugee', 'iraq', 'sudan'], \n",
    "                   ['happy', 'volunteer', 'help', 'give', 'support']]\n",
    "\n",
    "seed_topics = {}\n",
    "for t_id, st in enumerate(seed_topic_list):\n",
    "    for word in st:\n",
    "        seed_topics[word2id[word]] = t_id\n",
    "\n",
    "model.fit(X, seed_topics=seed_topics, seed_confidence=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: thank support calling unhcr im donation help usa refugees hello\n",
      "Topic 1: know just im like dont want people thats okay right\n",
      "Topic 2: okay thank calling name right yes please information address usa\n",
      "Topic 3: support thank monthly im families winter just help want refugee\n",
      "Topic 4: thank calling hello im unhcr usa okay name may please\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "topic_word = model.topic_word_\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "     topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "     print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210852"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_names.index('syria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for element in (X[:, 210852]):\n",
    "    if element != 0:\n",
    "        count+=1\n",
    "        \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
